{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xuyFCmBFNw4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages\\transformers\\models\\trocr\\processing_trocr.py:137: FutureWarning: `feature_extractor` is deprecated and will be removed in v5. Use `image_processor` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='116325' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [     4/116325 02:46 < 2685:15:00, 0.01 it/s, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    TrOCRProcessor,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    default_data_collator\n",
    ")\n",
    "\n",
    "block_plot = False\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "\n",
    "def seed_everything(seed_value):\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    BATCH_SIZE:    int = 30\n",
    "    EPOCHS:        int = 5\n",
    "    LEARNING_RATE: float = 0.0001\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelConfig:\n",
    "    MODEL_NAME: str = 'microsoft/trocr-small-handwritten'\n",
    "\n",
    "# EMNIST Dataset Transformation to correct orientation and convert to RGB\n",
    "emnist_correction = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: x.rotate(-90)),  # Rotate 90 degrees clockwise\n",
    "    transforms.Lambda(lambda x: x.transpose(Image.FLIP_LEFT_RIGHT)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "])\n",
    "\n",
    "# Data Augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.5),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 3)),\n",
    "])\n",
    "\n",
    "class EMNISTDataset(Dataset):\n",
    "    def __init__(self, emnist_dataset, processor, max_target_length=4):\n",
    "        self.emnist_dataset = emnist_dataset\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "        self.label_to_char = self._create_label_mapping()\n",
    "\n",
    "    def _create_label_mapping(self):\n",
    "        label_to_char = {}\n",
    "        for idx in range(62):\n",
    "            if idx < 10:\n",
    "                label_to_char[idx] = str(idx)\n",
    "            elif idx < 36:\n",
    "                label_to_char[idx] = chr(65 + idx - 10)\n",
    "            else:\n",
    "                label_to_char[idx] = chr(97 + idx - 36)\n",
    "        return label_to_char\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.emnist_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label_idx = self.emnist_dataset[idx]\n",
    "        image = train_transforms(image)\n",
    "        pixel_values = self.processor(image, return_tensors='pt').pixel_values\n",
    "        text = self.label_to_char[label_idx]\n",
    "\n",
    "        labels = self.processor.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_target_length\n",
    "        ).input_ids\n",
    "\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values.squeeze(),\n",
    "            \"labels\": torch.tensor(labels)\n",
    "        }\n",
    "\n",
    "# Load EMNIST datasets\n",
    "emnist_train = datasets.EMNIST(\n",
    "    root='./data',\n",
    "    split='byclass',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=emnist_correction\n",
    ")\n",
    "\n",
    "emnist_test = datasets.EMNIST(\n",
    "    root='./data',\n",
    "    split='byclass',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=emnist_correction\n",
    ")\n",
    "\n",
    "# Initialize processor and datasets\n",
    "processor = TrOCRProcessor.from_pretrained(ModelConfig.MODEL_NAME)\n",
    "train_dataset = EMNISTDataset(emnist_train, processor)\n",
    "valid_dataset = EMNISTDataset(emnist_test, processor)\n",
    "\n",
    "# Initialize model\n",
    "model = VisionEncoderDecoderModel.from_pretrained(ModelConfig.MODEL_NAME)\n",
    "model.to(device)\n",
    "\n",
    "# Model configuration adjustments\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 4  # Adjusted for single character prediction\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 0\n",
    "model.config.length_penalty = 1.0\n",
    "model.config.num_beams = 1\n",
    "\n",
    "# Metrics\n",
    "cer_metric = evaluate.load('cer')\n",
    "\n",
    "def compute_cer(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    return {\"cer\": cer}\n",
    "\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=TrainingConfig.BATCH_SIZE,\n",
    "    per_device_eval_batch_size=TrainingConfig.BATCH_SIZE,\n",
    "    fp16=True,\n",
    "    output_dir='trocr-emnist-model',\n",
    "    logging_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=3,\n",
    "    report_to='tensorboard',\n",
    "    num_train_epochs=TrainingConfig.EPOCHS\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.feature_extractor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_cer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=default_data_collator  # Use the default data collator\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model\n",
    "model.save_pretrained(\"trocr-emnist-final\")\n",
    "processor.save_pretrained(\"trocr-emnist-final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ajzwp5TjoWPt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\KIIT\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q sentencepiece\n",
    "!pip install -q jiwer\n",
    "!pip install -q datasets\n",
    "!pip install -q evaluate\n",
    "!pip install -q -U accelerate\n",
    "\n",
    "!pip install -q matplotlib\n",
    "!pip install -q protobuf==3.20.1\n",
    "!pip install -q tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6t6ZFf3q7xX"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.44"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
